{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66312a3c-d492-4642-abce-7e326d2ae7f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61391200-6d9b-4de6-9abc-2570fa1b3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "sagemaker-ap-south-1-057641535369\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install huggingface_hub\n",
    "!pip install PIL\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "import sagemaker\n",
    "import shutil\n",
    "from distutils.dir_util import copy_tree\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import sagemaker\n",
    "from huggingface_hub import snapshot_download\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import tarfile\n",
    "import os\n",
    "import json \n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "sess = sagemaker.Session(boto3.session.Session())\n",
    "bucket=sess.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7084e5d8-abec-4347-b10e-26d7f14ef649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "technique='tile'\n",
    "os.makedirs(f'script/{technique}/',exist_ok=True)\n",
    "os.makedirs(f'compressed/{technique}/',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16a87a53-5b40-4f08-bb1f-40cd221e9fef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/tile/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/tile/inference.py\n",
    "import json\n",
    "import torch\n",
    "from diffusers import ControlNetModel, StableDiffusionControlNetImg2ImgPipeline, DPMSolverMultistepScheduler\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "def _encode(image):\n",
    "    img = image\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    img.save(img_byte_arr, format='PNG')\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "    img_byte_arr=base64.b64encode(img_byte_arr).decode()\n",
    "    return img_byte_arr\n",
    "\n",
    "def _decode(image):\n",
    "    image=base64.b64decode(image)\n",
    "    image=Image.open(io.BytesIO(image))\n",
    "    return image\n",
    "\n",
    "def model_fn(model_dir, extra):\n",
    "    device = \"cuda\"\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "    controlnet1 = ControlNetModel.from_pretrained(f\"{model_dir}/lllyasviel-1\",torch_dtype=torch_dtype).to(device)\n",
    "    controlnet2 = ControlNetModel.from_pretrained(f\"{model_dir}/lllyasviel-1\",torch_dtype=torch_dtype).to(device)\n",
    "    controlnet3 = ControlNetModel.from_pretrained(f\"{model_dir}/lllyasviel-2\",torch_dtype=torch_dtype).to(device)\n",
    "\n",
    "    pipe = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(f\"{model_dir}/sinkinai-0\", controlnet=[controlnet1,controlnet2, controlnet3], torch_dtype=torch_dtype).to(device)\n",
    "\n",
    "    # Sampler: DPM++ 2M Karras,\n",
    "    # https://github.com/huggingface/diffusers/issues/1887\n",
    "    # https://github.com/huggingface/diffusers/issues/1633\n",
    "\n",
    "    # dpmsolver or dpmsolver++ or sde-dpmsolver or sde-dpmsolver++\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config, use_karras_sigmas=True, algorithm_type=\"dpmsolver++\")\n",
    "    pipe.enable_xformers_memory_efficient_attention()\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    \n",
    "    return pipe\n",
    "\n",
    "\n",
    "def transform_fn(model, data, input_content_type, output_content_type):\n",
    "   \n",
    "    #parse inference input\n",
    "    input_data=json.loads(data)\n",
    "\n",
    "    \"\"\"\n",
    "    Expected request format :\n",
    "    request={\n",
    "         \"prompt\":p_prompt,\n",
    "         \"negative_prompt\":n_prompt,\n",
    "         \"starting_image\":starting_image.decode(),\n",
    "         \"controlnet_1_image\":cnet_image_1.decode(),\n",
    "         \"controlnet_2_image\":cnet_image_2.decode(),\n",
    "         \"controlnet_3_image\":cnet_image_3.decode(),\n",
    "         \"seed\": 1441837673,\n",
    "         \"num_inference_steps\": 50,\n",
    "         \"num_images_per_prompt\": 1,\n",
    "         \"strength\": 0.75,\n",
    "         \"guidance_scale\": 7.00,\n",
    "         \"controlnet_1_conditioning_scale\": 0.85,\n",
    "         \"controlnet_1_guidance_start\": 0.23,\n",
    "         \"controlnet_1_guidance_end\": 0.96,\n",
    "         \"controlnet_2_conditioning_scale\": 0.65,\n",
    "         \"controlnet_2_guidance_start\": 0.18,\n",
    "         \"controlnet_2_guidance_end\": 0.80,\n",
    "         \"controlnet_3_conditioning_scale\": 0.65,\n",
    "         \"controlnet_3_guidance_start\": 0.18,\n",
    "         \"controlnet_3_guidance_end\": 0.80\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    #set defaults if not provided during inference\n",
    "    seed=int(input_data[\"seed\"])  if \"seed\" in input_data.keys() else 1441837673\n",
    "    num_inference_steps=int(input_data[\"num_inference_steps\"])  if \"num_inference_steps\" in input_data.keys() else 50\n",
    "    num_images_per_prompt=int(input_data[\"num_images_per_prompt\"])  if \"num_images_per_prompt\" in input_data.keys() else 1\n",
    "    strength=float(input_data[\"strength\"])  if \"strength\" in input_data.keys() else 0.75\n",
    "    guidance_scale=float(input_data[\"guidance_scale\"])  if \"guidance_scale\" in input_data.keys() else 7.00\n",
    "    \n",
    "    controlnet_1_conditioning_scale=float(input_data[\"controlnet_1_conditioning_scale\"])  if \"controlnet_1_conditioning_scale\" in input_data.keys() else 0.85\n",
    "    controlnet_2_conditioning_scale=float(input_data[\"controlnet_2_conditioning_scale\"])  if \"controlnet_2_conditioning_scale\" in input_data.keys() else 0.65\n",
    "    controlnet_3_conditioning_scale=float(input_data[\"controlnet_3_conditioning_scale\"])  if \"controlnet_3_conditioning_scale\" in input_data.keys() else 0.65\n",
    "    controlnet_conditioning_scale_list = [controlnet_1_conditioning_scale, controlnet_2_conditioning_scale, controlnet_3_conditioning_scale]\n",
    "\n",
    "    controlnet_1_guidance_start=float(input_data[\"controlnet_1_guidance_start\"])  if \"controlnet_1_guidance_start\" in input_data.keys() else 0.23\n",
    "    controlnet_2_guidance_start=float(input_data[\"controlnet_2_guidance_start\"])  if \"controlnet_2_guidance_start\" in input_data.keys() else 0.18\n",
    "    controlnet_3_guidance_start=float(input_data[\"controlnet_3_guidance_start\"])  if \"controlnet_3_guidance_start\" in input_data.keys() else 0.18\n",
    "    control_guidance_start_list = [controlnet_1_guidance_start, controlnet_2_guidance_start, controlnet_3_guidance_start]\n",
    "    \n",
    "    controlnet_1_guidance_end=float(input_data[\"controlnet_1_guidance_end\"])  if \"controlnet_1_guidance_end\" in input_data.keys() else 0.96\n",
    "    controlnet_2_guidance_end=float(input_data[\"controlnet_2_guidance_end\"])  if \"controlnet_2_guidance_end\" in input_data.keys() else 0.80\n",
    "    controlnet_3_guidance_end=float(input_data[\"controlnet_3_guidance_end\"])  if \"controlnet_3_guidance_end\" in input_data.keys() else 0.80\n",
    "    control_guidance_end_list = [controlnet_1_guidance_end, controlnet_2_guidance_end, controlnet_3_guidance_end]\n",
    "    \n",
    "    starting_image = _decode(input_data['starting_image'])\n",
    "    controlnet_1_image = _decode(input_data['controlnet_1_image'])\n",
    "    controlnet_2_image = _decode(input_data['controlnet_2_image'])\n",
    "    controlnet_3_image = _decode(input_data['controlnet_3_image'])\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        generator = torch.Generator('cuda').manual_seed(seed)\n",
    "    else:\n",
    "        generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    # Generate output image(s)\n",
    "    output_images = model(\n",
    "        image=starting_image,\n",
    "        control_image=[controlnet_1_image, controlnet_2_image, controlnet_3_image],\n",
    "        controlnet_conditioning_scale=controlnet_conditioning_scale_list,\n",
    "        control_guidance_start=control_guidance_start_list,\n",
    "        control_guidance_end=control_guidance_end_list,\n",
    "        prompt=input_data[\"prompt\"],\n",
    "        negative_prompt=input_data[\"negative_prompt\"],\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "        strength=strength,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=generator\n",
    "    ).images\n",
    "\n",
    "    response_list = []\n",
    "    \n",
    "    for image in output_images:\n",
    "        encoded_output = _encode(image)\n",
    "        response_list.append(encoded_output)\n",
    "    \n",
    "    response={\n",
    "        \"output_images\":response_list\n",
    "    }\n",
    "    return response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5b77bb2-66ce-4eca-9f08-7864743f2a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/tile/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/tile/requirements.txt\n",
    "diffusers==0.19.3\n",
    "accelerate\n",
    "opencv-contrib-python\n",
    "controlnet-aux\n",
    "xformers==0.0.20\n",
    "opencv-python-headless\n",
    "transformers\n",
    "qrcode\n",
    "rembg\n",
    "boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a91ce73-40a2-4383-90d4-349a6b9b855f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297c33c9dd074507adf66f3f10a7b174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985740042c35495bab6cac3873eb6ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)ature_extractor/preprocessor_config.json:   0%|          | 0.00/520 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de8012d7b114d3d8c75b04386af2983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f9284a22b34c5580c7ff42c14e7812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c18cbb3f1624f82810ef9fe699213d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5532db2d93074144b22e62329aa518e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b206547897244f63bedbbf9f9a4a9274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7346ec86f80495e83fe139812cdedb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "safety_checker/config.json:   0%|          | 0.00/4.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90aef1f67651429f914784064c2be343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/pytorch_model.bin:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de8cdc076a743d89242347044ae391e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "safety_checker/pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a220d5ccc04383b98da2eb08222c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8251c2cbc9a54e14bdf083a4bd008b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4437d89336534a6a8e8324e7dd09898b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c0a9983cc94361aadfca9f68b9d1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f76ee414f25483693060fcf3b7eb0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccae41b7a4841e9b7e5781d8b734a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/diffusion_pytorch_model.bin:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26886472cab4bc48497c3647494c35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/diffusion_pytorch_model.bin:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2617d5c1a1f24c7b8806a411a65e7148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433c07237bfa4383a08274808bee36c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/output.png:   0%|          | 0.00/1.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba745575f7145799467d04fce4deb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.bin:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ca241f0eb746988e181cfb948e5d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/original.png:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ea6261990549629623eb31848623c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/955 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539f0d184a5945f5b055ecddaddec75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sd.png:   0%|          | 0.00/59.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48cf278481842cdbc3727d9c6f1f1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486eef5840bd4573a422a742ed1c61d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f55b0e5b3f1455cbe82571f209bf9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfd183758cd4e80a1cfbe883a04ab7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/723M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee899f81b7044779d751b5a01908c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d9e591e75640bc9b497bc9530fcbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97519bebff2e4a39b13f8a77b011b704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "control_net_canny.py:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7091fbb497145daa7ef369260eafa5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d469cafb014321952c620bd4125484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.bin:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca47404acc14ae081224cf82afcc167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.fp16.bin:   0%|          | 0.00/723M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce2a8b3e7f543d4b335109fb6d63610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a325f66f4f848bcb8e43d175455383d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/bird_canny_out.png:   0%|          | 0.00/835k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e980d62df23b4b42a7e850a27c4a5c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/control.png:   0%|          | 0.00/29.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f9cda3fca94c1ea3090621b5ed1ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/bird_canny.png:   0%|          | 0.00/29.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4425406cfd948a48ab4049ca2ec3aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/bird.png:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c50b7f20bd4a95a3354de41503089f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/image_out.png:   0%|          | 0.00/835k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1f315d6e8f400dba30b73e3b1d1fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sd.png:   0%|          | 0.00/59.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a764e2e38c400c9d2e97cd8304ed10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images/input.png:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 1s, sys: 44.5 s, total: 9min 46s\n",
      "Wall time: 14min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_id = [\"sinkinai/GhostMix-V2-BakedVAE\",\"lllyasviel/control_v11f1e_sd15_tile\",\"lllyasviel/control_v11p_sd15_canny\"]\n",
    "\n",
    "# Creating a tarfile to to compress our model to a `tar.gz` format as required by SageMaker\n",
    "tar = tarfile.open(f\"compressed/tile/tile.tar.gz\", \"w:gz\",compresslevel=2)\n",
    "counter=0\n",
    "for ids in model_id:\n",
    "    \n",
    "    model_tar_dir = Path(ids.split(\"/\")[0] +\"-\"+ str(counter))\n",
    "    if model_tar_dir.exists():\n",
    "        shutil.rmtree(str(model_tar_dir))\n",
    "    model_tar_dir.mkdir(exist_ok=True)    \n",
    "    name=ids.split(\"/\")[0]+\"-\"+ str(counter)\n",
    "    \n",
    "    snapshot_download(ids, local_dir=str(model_tar_dir), local_dir_use_symlinks=False) \n",
    "    tar.add(str(model_tar_dir),arcname=name)\n",
    "    counter = counter + 1\n",
    "    #!rm -r {str(model_tar_dir)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a895be2-f951-447b-9d06-bd295b4c219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the inference scripts and requirements file to the tarfile\n",
    "tar.add(f\"script/tile/\",arcname='code')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc1ccf-a8d3-4440-8610-81a352a934e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bc42c66-375c-4cdd-8739-cac7b1a05579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: compressed/tile/tile.tar.gz to s3://sagemaker-ap-south-1-057641535369/model_controlnet/tile.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_s3_uri=f\"s3://{bucket}/model_controlnet/{technique}.tar.gz\"\n",
    "!aws s3 cp compressed/{technique}/{technique}.tar.gz {model_s3_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6da2d5-4111-4ce4-8fd3-2163365a55f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21f0ae0b-6829-4496-a9dd-907aefeb7f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "image_uri =\"763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-inference:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04\"\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=model_s3_uri,  # path to your trained sagemaker model\n",
    "   role=get_execution_role(), # iam role with permissions to create an Endpoint  \n",
    "   py_version=\"py39\", # python version of the DLC  \n",
    "   image_uri=image_uri, # sagemaker container image uri \n",
    "   env={\n",
    "       \"MMS_MAX_REQUEST_SIZE\": \"2000000000\", \n",
    "       \"MMS_MAX_RESPONSE_SIZE\": \"2000000000\",\n",
    "       \"MMS_DEFAULT_RESPONSE_TIMEOUT\": '9000',\n",
    "       \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "       \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
    "       \"SAGEMAKER_REGION\": \"ap-south-1\",\n",
    "       \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n",
    "   }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ea5825e-739a-4b19-9445-a4929876c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "from sagemaker.s3 import s3_path_join\n",
    "\n",
    "# create async endpoint configuration\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=s3_path_join(\"s3://\",bucket,\"qart_async_inference/output\"),\n",
    "    #notification_config={\n",
    "            #   \"SuccessTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "            #   \"ErrorTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "    # }, #  Notification configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cdb99a6-a276-4f2d-9b0d-27231a8f1502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!CPU times: user 204 ms, sys: 14 ms, total: 218 ms\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Deploying the model\n",
    "from sagemaker.deserializers import JSONDeserializer,NumpyDeserializer\n",
    "from sagemaker.serializers import CSVSerializer, JSONSerializer, IdentitySerializer\n",
    "import datetime\n",
    "\n",
    "ts = \"{}\".format(datetime.datetime.now().strftime(\"%d-%m-%y-%H-%M-%S\"))\n",
    "endpoint_name = \"qart-face-async-tile-canny-\"+ts\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=2,\n",
    "    instance_type= \"ml.g4dn.4xlarge\",\n",
    "    async_inference_config=async_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fba238-6759-4d90-a3fa-031b848f322b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
